# -*- coding: utf-8 -*-
"""alfaz_HeartFailurePrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TWRIVYDJxsFoqxqzntMX_ENIDklSQNO0

# Importing Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""# Importing Dataset"""

dataset = pd.read_csv('heart.csv')
x = dataset.iloc[:,:-1].values
y = dataset.iloc[:,-1].values

print(x[1])

print(y)

"""# Data Preprocessing

# Label Encoding
"""

from sklearn.preprocessing import LabelEncoder
le1 = LabelEncoder()
le2 = LabelEncoder()
le6 = LabelEncoder()
le8 = LabelEncoder()
le10 = LabelEncoder()
x[:,1] = le1.fit_transform(x[:,1])
x[:,2] = le2.fit_transform(x[:,2])
x[:,6] = le6.fit_transform(x[:,6])
x[:,8] = le8.fit_transform(x[:,8])
x[:,10] = le10.fit_transform(x[:,10])

print(x)

print(y)

"""# Splitting Dataset into Training set and Test set"""

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.2,random_state=0)

"""# Feature Scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.fit_transform(X_test)

print(X_test)

"""# Training Dataset

##Training with Random Forest Classifier
"""

from sklearn.ensemble import RandomForestClassifier
model_randomforest = RandomForestClassifier()
model_randomforest.fit(X_train,Y_train)

from sklearn.linear_model import LogisticRegression
model_logistic = LogisticRegression()
model_logistic.fit(X_train,Y_train)

from sklearn.neighbors import KNeighborsClassifier
model_kneighbors = KNeighborsClassifier()
model_kneighbors.fit(X_train,Y_train)

from sklearn.tree import DecisionTreeClassifier
model_decision = DecisionTreeClassifier()
model_decision.fit(X_train,Y_train)

from xgboost import XGBClassifier
model_xgb = XGBClassifier()
model_xgb.fit(X_train,Y_train)

from sklearn.svm import SVC
model_svm = SVC()
model_svm.fit(X_train,Y_train)

"""# Making Confusion Matrix"""

from sklearn.metrics import confusion_matrix , accuracy_score
# cm = confusion_matrix(Y_test,y_pred_random)
# print(cm)

y_pred_logistic = model_logistic.predict(X_test)
y_pred_neighbors = model_kneighbors.predict(X_test)
y_pred_svm = model_svm.predict(X_test)
y_pred_decision = model_decision.predict(X_test)
y_pred_random = model_randomforest.predict(X_test)
y_pred_xgb = model_xgb.predict(X_test)

RandomForest_Accuracy = accuracy_score(Y_test,y_pred_random)
LogisticRegression_Accuracy = accuracy_score(Y_test,y_pred_logistic)
KNeighbors_Accuracy = accuracy_score(Y_test,y_pred_neighbors)
SVM_Accuracy = accuracy_score(Y_test,y_pred_svm)
Decision_Accuracy = accuracy_score(Y_test,y_pred_decision)
XGBoost_Accuracy = accuracy_score(Y_test,y_pred_xgb)

plt.figure(figsize=(12, 6))
models = ["Logistic Regression", "KNeighbors", "Support Vector Machine", "Decision Tree", "Random Forest", "XGBoost"]
accuracies = [LogisticRegression_Accuracy, KNeighbors_Accuracy, SVM_Accuracy, Decision_Accuracy, RandomForest_Accuracy, XGBoost_Accuracy]

bars = plt.bar(models, accuracies, width=0.6)

plt.xlabel("Machine Learning Algorithm")
plt.ylabel("Accuracy")
plt.title("Accuracy of Different Machine Learning Models")
plt.ylim(0, 1.0) # Set y-axis limit to 0-1 for accuracy

# Add accuracy values on top of the bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')

plt.show()

print("Random Forest Accuracy:", RandomForest_Accuracy)
print("Logistic Regression Accuracy:", LogisticRegression_Accuracy)
print("KNeighbors Accuracy:", KNeighbors_Accuracy)
print("SVM Accuracy:", SVM_Accuracy)
print("Decision Tree Accuracy:", Decision_Accuracy)
print("XGBoost Accuracy:", XGBoost_Accuracy)

"""# Single Prediction
### age=40,Sex=M,chestpain = NAP,RestingBP=110,cholestrol=290,FastingBS=1,Resting ECG=ST,MaxHR=160,Exercise Angina=Y,oldpeak=2.2,ST_slope=Flat
"""

result2 = model_kneighbors.predict(
    sc.transform([[49, 0, 2, 160, 180, 0, 1, 156, 0, 1.0, 1]])
)

if result2 == [0]:
    print("Sample 2: Person Not Having Heart Disease")
else:
    print("Sample 2: Person Having Heart Disease")

"""# Task
Visualize all data.

## Visualize numerical features

### Subtask:
Create histograms and box plots for numerical features to understand their distribution and relationship with the target variable.

**Reasoning**:
Identify numerical columns and create histograms and box plots for each numerical column, colored by the target variable, to visualize their distribution and relationship with the target variable as requested in the instructions.
"""

numerical_cols = dataset.select_dtypes(include=np.number).columns.tolist()

for col in numerical_cols:
    if col != 'HeartDisease':
        # Histogram
        plt.figure(figsize=(10, 6))
        dataset[dataset['HeartDisease'] == 0][col].hist(alpha=0.5, color='blue', label='No Heart Disease')
        dataset[dataset['HeartDisease'] == 1][col].hist(alpha=0.5, color='red', label='Heart Disease')
        plt.xlabel(col)
        plt.ylabel("Frequency")
        plt.title(f"Distribution of {col} by Heart Disease")
        plt.legend()
        plt.show()

        # Box plot
        plt.figure(figsize=(10, 6))
        dataset.boxplot(column=col, by='HeartDisease')
        plt.xlabel("Heart Disease (0: No, 1: Yes)")
        plt.ylabel(col)
        plt.title(f"Box plot of {col} by Heart Disease")
        plt.suptitle("") # Suppress the default title
        plt.show()

